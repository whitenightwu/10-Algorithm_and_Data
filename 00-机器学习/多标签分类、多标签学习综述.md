# 多标签分类、多标签学习
预测非互斥分类的任务。"想象一下，人们可能会把多个标签同时标注在自己的某篇技术类博客文章上，例如“机器学习”、“科技”、“编程语言”、“云计算”、“安全与隐私”和“AWS”。这里面的标签其实有时候相互关联，比如“云计算”和“安全与隐私”。


**一个同属于监督学习并和多标签分类很相关的问题就是排序问题（ranking）**。排序任务是对一个标签集排序，使得排在前面的标签与相应实例更相关。

在特定分类问题中，标签属于一个层次结构（hierarchical structure）。当数据集标签属于一个层次结构的时候，我们这个任务为层次分类，如果一个样本与层次结构的多个节点相关， 那么这个任务就被称为层次多标签分类。

多实例学习（multiple-instance learning）是监督学习的一个变种，用的比较少 ，就不说了。

## 具体算法
1）0层或多层的hidden layer + Softmax：label弄成向量如[0 1 0 1 0 0 1]，Loss Function是CE的话，做加和(/sum(label))就行（即将label从one-hot改成multi-hot），Softmax求导里面有一个点乘label，所以参数矩阵W迭代会更新到对应W的行(或列)上面–完全的Deep Learning套路，这其实就是Hinton的《Distilling the Knowledge in a Neural Network 》中提的 the soft targets。

2）Multi-dimension Logistic Regression[0层或多层的hidden layer + Sigmoid, 类Deep Learning方法]：训练过程和1）差不多，与Softmax的差别在于训练过程最后层概率不做Normalization。

3）在softmax层之前加入一个coding层，每一种分类用一个bit位表示。
coding层具体是用sigmoid激活函数，阈值设为0.5.如果值大于0.5，则属于此标签，小于0.5，则不属于这个标签。

4）Classifier Chains，把原问题分解成有先后顺序的一系列Binary Classification，然后前边的Binary Classification会对后边的产生影响；

5）Calibrated label ranking，这个有点像Multi-Classification中One vs One的策略，就是通过两两对比，然后进行投票决定分类效果。

## 依据解决问题的角度分类
1）基于问题转化（Problem Transformation）的方法。基于问题转化的多标记分类是转化问题数据，使之适用现有算法。

代表性学习算法LP，Binary Relevance，Calibrated Label Ranking， Random k-labelsets。总体来说，这类方法有考虑类标之间的联系，但是对于类标较多、数据量较大的数据集，这类方法的计算复杂度是一个很明显的缺陷。


2）基于算法适应的方法和算法适应方法（Algorithm Adaptation）。

基于算法适应的方法是指针对某一特定的算法进行扩展，从而能够直接处理多标记数据，改进算法，适应数据。问题转化方法是将多标记问题转化成一个或者多个单类标问题，算法适应方法是在多标记的基础上研究算法。

近年来，用于多标记的算法适应的算法越来越多，代表性学习算法ML-kNN，Rank-SVM，LEAD，CML。


## 对于分类策略，基于考察标记之间相关性的不同方式
1）First-Order Strategy: 考虑的是label之间相互独立，那么就可以把Multi-label问题转换为普通的分类问题。如果一个Label有多类的话，那么就用传统的One vs All来解决。

Binary Relevance：该类策略通过逐一考察单个标记而忽略标记之间的相关性，如将多标记学习问题分解为个独立的二类分类问题，从而构造多标记学习系统。该类方法效率较高且实现简单，但由于其完全忽略标记之间可能存在的相关性，其系统的泛化性能往往较低。”

2）Second-Order Strategy: 这一类是考虑Label之间的两两相关性，结果会导致计算复杂度有显著的增加。

3）High-Order Strategy: 这个就是考虑多Label之间的相关性，计算复杂度会更高。


## 论外（与无监督学习的关系）
弱监督学习的目的，与监督学习一致，然而其获得的样本并没有完整的标记。从标记缺失的形式和处理方式的不同，又可以分为半监督学习、主动学习、多示例学习／多标记学习、和强化学习。

1）半监督学习中，只有少量的样本具有标记；
2）主动学习中，机器可以询问真实的标记，但需要考虑询问的代价；
3）多示例学习中，一个对象表示为一组样本的包，而标记只在包的层面上，在样本的层面上却没有标记；
4）多标记学习中，一个样本对应一组标记，因此需要处理巨大的标记组合空间问题；
5）强化学习中，机器需要探索环境来获得样本，并且学习的目的是长期的奖赏，因此样本的标记是延迟的。

# 参考资料
+++中国机器学习2015白皮书
https://blog.csdn.net/qq_27009517/article/details/80264919