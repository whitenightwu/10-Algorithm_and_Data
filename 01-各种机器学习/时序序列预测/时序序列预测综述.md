# 时间序列预测（Time series Forecasting）
属于数据挖掘中的一类。
时间序列预测分析就是利用过去一段时间内某事件时间的特征来预测未来一段时间内该事件的特征。
这是一类相对比较复杂的预测建模问题，和回归分析模型的预测不同，时间序列模型是依赖于事件发生的先后顺序的，同样大小的值改变顺序后输入模型产生的结果是不同的。
时间序列的本质特性是承认动态数据之间的相关性或依赖关系，这种相关性表征了系统的“动态”或“记忆”。如果这种相关性可用数学模型描述，则可有系统的过去及现在的取值预测其未来取值。
注意，时间序列可以分为两种，1）平稳序列，即存在某种周期，季节性及趋势的方差和均值不随时间变化的序列；2）非平稳序列。

生活中有很多序列数据都属于时间序列的范畴，比如股票指数、心脑电图，甚至语音信号、草原某地的风速等等，都是有其内在特征的变化。

对于一个时间序列，通常可以从四个方面来考虑数据的特性：趋势性（Trend）、季节性（Seasonal）、周期性（Cyclical）、随机性（Irregular）。
1）如果一个时间序列从总体上来看是逐渐增加的、或者减少的、或者保持稳定的，那么该时间序列具有趋势性。
2）季节性因素（一年中的不同季度、一周中的工作日和周末、一年中特定的节日、气候等等）的影响，那么时间序列数据就会带有季节性。比如冰棍的销售量通常会在夏天突然增长；在节假日周日，游客数量会增加。具有季节性的时序序列数据通常是以一个固定且可知的频率变化。很多时候有季节性的时间序列也有趋势性。
3）周期性是时间序列中长期的变化趋势，周期性的变化频率是不可知的，但数据从中长期来看会出现相同的模式，通常是2年及以上时间。
4）随机性指的是不可预知的部分，这些影响不规则且在特定模式中不会重复。


对于其性质随时间是稳定不变的信号（平稳随机过程），处理的理想工具仍然是傅立叶分析。但是在实际应用中的绝大多数信号是非稳定的（非平稳随机过程），而特别适用于非稳定信号的工具就是小波分析。
通常判断数据周期性的方法是对数据进行傅里叶变换。


## 主流算法
时间序列预测像游程，多维卡方，列联表，Spearman\Kendall秩相关检验，Cochran,Friedman,K-W检验，都是在分析数据的性质，做不出来预测。唯一能做预测的似乎是由列联表近似出的对数线性模型，但也是要估计的。

移动平均分解法，指数平滑法(HoltWinters)，局部加权回归法（LOESS），自回归整合移动平均（ARIMA）
时间序列预测法。包括：简单序时平均数法、加权序时平均数法、移动平均法、加权移动平均法、趋势预测法、指数平滑法、季节性趋势预测法、市场寿命周期预测法等。
统计回归。包括：一元线性回归、多元线性回归、正交多项回归、差值回归等。
比较先进复杂一些的有：灰色预测、神经网络预测、模糊预测、马尔科夫预测等。
还有专门的模型预测，例如自然增长模型去预测人口增长。另外，有不少经济预测模型和传染病模型都是经过时间检验的，如果预测内容合适，直接套用的话是快捷又准确，缺点是不够细。

多项式加权求和的缺点是模型未对转折点处做约束。
对于时间序列模式识别目前的方法主要涉及到两个方向：一个叫做复杂系统，另外一个是机器学习。复杂系统是需要将数据拟合到已知的模型当中，比如古典的AR、MA、ARMA、自回归移动平均模型ARIMA。而机器学习在用一类通用模型，例如神经网络，进行“暴力”拟合。

### 移动平均（MA，moving average）
移动平均模型可能是最简单的时间序列建模方法。这个模型简单来说就是，下一个值是所有过去值的平均值。
移动平均模型认为xt主要受过去q期的误差项影响。分为三项，
1）在t时刻的随机变量Xt的取值Xt是前q期的随机扰动εt-1,εt−2,...,εt−q的多元线性函数。
2）误差项是当期的随机干扰εt，为零均值白噪声序列。
3）过去q期真实序列{Xt}的均值。

移动平均值可用于识别数据中的趋势。窗口越长，趋势就越平滑。

### 指数平滑（Exponential Weighted Moving Average)、双指数平滑、三指数平滑
指数平滑法有几种不同形式：一次指数平滑法针对没有趋势和季节性的序列，二次指数平滑法针对有趋势但没有季节性的序列，三次指数平滑法针对有趋势也有季节性的序列。“Holt-Winters”有时特指三次指数平滑法。

一次指数平滑使用与移动平均相似的逻辑，不同的是它对每个观测值分配了不同的递减权重。换言之，离现在的时间距离越远，观察结果的重要性就越低。
核心概念是平滑因子alpha，它决定了之前观测值的权重下降的速度。它的值介于0和1之间，平滑因子越小，时间序列就越平滑，当平滑因子为0时就是移动平均模型。

双指数平滑。当时间序列中存在趋势时，使用双指数平滑，本质上只是指数平滑的两次递归使用。
核心概念是平滑因子alpha和趋势平滑因子beta。

三指数平滑。该方法通过添加季节平滑因子来扩展双指数平滑（在这里季节性就是周期性）。
在双指数平滑的基础上，增加了季节平滑因子gamma和季节长度L。


### 自回归模型（AR，AutoRegression Model）
自回归模型就是多元线性回归，认为xt主要受过去p期的序列值影响。分为两项，
1）前p期的真实序列Xt-1,Xt−2,...,Xt−q的多元线性函数。
2）误差项是当前的随机干扰εt，为零均值白噪声序列。


### ARMA模型
ARMA模型是时间序列分析中描述平稳时间序列自相关性的典型方法。基本思想是随机变量Xt的取值xt不仅与以前p期的序列值有关还与前q期的随机扰动有关。具体而言，ARMA算法就是将自回归（AR）的算子加上移动平均（MA，moving average）。


如果存在异方差，更合理的做法应该是联合ARIMA-GARCH模型、自回归移动平均模型ARIMA、ARMAX，一起估计参数，但这样参数估计难度较大。

季节性差分自回归滑动平均模型（SARIMA），SARIMA 实际上是简单模型的组合，可以生成一个复杂的模型，该模型可以模拟具有非平稳特性和季节性的时间序列。
在时间序列中，ARIMA模型是在ARMA模型的基础上多了差分的操作。


ARIMA用来对线性关系的数据更好地建模，而RNN(取决于激活函数)则更好地建立了具有非线性关系的模型数据。ARIMA模型为数据科学家提供了一个更优的选择，之后，当数据通过 Lee，White和Granger(LWG)检验之后的残差中仍然包含非线性关系时，可以用RNN这样的非线性模型对数据集进一步处理。

### GARCH模型





### STH分解
它将时间序列分解为周期项（Season），趋势项（Trend），节假日项（holiday）等。Facebook开源的prophet就是通过这样的分解来训练模型。
趋势项：前面提到，可以用线性函数、对数函数和指数函数拟合趋势项。facebook开源的prophet中使用了类似分段函数的思想，用逻辑斯蒂函数和线性函数作为作为增长函数。
周期项：常见的拟合周期数据的方式有傅里叶分解，周期核函数方法（比如使用ExpSineSquared核的高斯过程）。
使用周期核函数的高斯过程和Ridge回归需要特别指出，STH分解不是将数据分解为几部分再分别拟合，而是将模型写成三部分之和（根据数据的内在机理），再去拟合实际数据求解模型参数。模型怎么写，涉及到哪些参数，这是由对问题和数据的理解决定的。比如，趋势项和周期项之间可能是乘法关系：值越大，周期内的振幅越大，此时可以先求对数再用加法模型拟合。

### 信号分解
信号分解利用信号处理的方法，将时间序列分解为高频和低频信号。对于分离后的信号，再用ARIMA等模型拟合。最后，将各个部分的预测值叠加或重构，就得到预测值。整个过程分为三步：分解、训练模型并预测，重构。
常见的分解的方法有下面四种：傅里叶分解（FT）、小波分解（WD）、经验模态分解(EMD)和变分模态分解(VMD)。因此实际使用中多用对时域自适应的小波分解。在实际应用中EMD可能存在模态混叠现象，分离后的信号包含多个频率，影响精度。近几年，VMD方法也引起了不小的关注。
这和STH分解有本质上的不同，STH分解的是模型而不是数据。


### LN分解
LN分解就是将时间序列数据分为线性项（L）和非线性项（N），先对两部分分别预测/拟合，再将两部分的预测值相加得出最终预测值。
线性项L(t)，一般可以通过滑动平均（moving average）提取，即前一段时间的值累加再取平均。
非线性部分N(t)，N(t)=y(t)-L(t)，其中y(t)是真实值。非线性部分可以用非线性核方法或者神经网络训练等非线性方法拟合。

一种优化后的方案就是，将线性部分的预测值L(t)、原始数据的历史值和非线性部分的历史值三部分全部作为特征，训练一个非线性模型来拟合。


### DeepAR
DeepAR是一个自回归循环神经网络，使用递归神经网络 (RNN) 结合自回归 AR 来预测标量（一维）时间序列。


### 机器学习方法
主流算法是集成学习算法，例如xgboost，随机森林及SVM这些。主要是数据挖掘，而数据挖掘的方法关键在于特征工程，跟其他挖掘任务不同的是，时间序列的特征工程会使用滑动窗口，即计算滑动窗口内的数据指标，如最小值，最大值，均值，方差等来作为新的特征。


### 深度学习方法
对于深度学习方法，循环神经网络RNN用的最多也适合解决这类问题
最近在一些金融的基金类数据挖掘比赛中，经过人类专家细调的LSTM大放异彩，展现出惊人的能力，尽管对硬件和时间要求较高，但LSTM模型在精确度上已经大幅超越传统滑窗+手工特征+GBDT。

对于节假日可以进行01编码或者one-hot编码

-------------
## 对预测结果的评估方法，分析特征的具体情况
**见《检验方法和指标综述.md》**


## 实际使用
对于无规律的时序，大家就别在不做任何处理的情况下上什么算法，都是扯淡和浪费时间，别被测试集的表象所蒙蔽了。而对于有周期、有规律的时序，上什么算法都会达到很好的效果。所以本身有一定规律才好做模型。


拟合如此接近，只能说明有专门的补单，数据都是做出来的。



对于大促，应该使用二次多项式、三次多项式，因为很好预测
一次 二次拟合 三次拟合 四次拟合……十次拟合，总有一次蒙对的。什么，还不对？那负一次，负二次继续啊，R²=0.9994又不是啥难事，实验拟合经常要做到R²=1.0000。
指数拟合，对数拟合，根本没在怕

对于无明显周期和非平稳时序数据，直接预测难以达到满意效果，可以利用经验模式分解(empirical mode decomposition,EMD)和长短期记忆(long short-term memory, LSTM)的组合算法应用于时序预测。
所谓经验模式分解，能使复杂信号分解为有限个本征模函数（Intrinsic Mode Function，简称IMF），所分解出来的各IMF分量包含了原信号的不同时间尺度的局部特征信号，可以达到降噪的目的。



一般不建议拿原始时间序列直接做预测，如果不想花费时间经历去提取特征，想直接就用算法预测的话，可以优先尝试三次指数平滑算法，预测效果相对会好一些。
复杂的时间序列预测，关键在于特征的提取，例如：您可以通过小波分解的方法将时间序列分解为趋势项、季节项和随机项，然后针对每个分序列进行预测。对于不平稳的时间序列建议进行差分，一般在3阶以内的差分就可以平稳，然后再对差分后的时间序列进行预测。
至于预测算法的选择，您可参考kaggle的web traffic预测，预测效果较好的算法有：LSTM）长短期记忆网络）\GRU（门控循环单元）\TCN（时间卷积网络）等。

模型在其次，关键还是特征啊。

建议先用自相关、偏自相关图和adf检验看一下特征的具体情况，然后再来分析用什么算法
协方差
QQ-plot
QQ图和概率图是比较数据的概率分布和其他理论的分布。


## 常用包和库
EViews是Econometrics Views的缩写，通常称为计量经济学软件包。对于时序模型而言，EViews里面的工具比python更强大
python的statmodels库
Facebook开源的prophet
时间序列的特征提取工具 tsfresh
包pmdarima（alkaline-ml开源的）。


## trick
让每一个输入都有很规范的格式。每一个输入源必须是mean 0，variance 1。假如说不能直接用价格；要用价格的差距。
先排除那些没有用的输入。



# 参考资料
https://www.zhihu.com/question/21229371/answer/623457296
https://zhuanlan.zhihu.com/p/81327191
https://zhuanlan.zhihu.com/p/43353740
https://www.zhihu.com/question/318020413/answer/711641333
https://blog.csdn.net/qq_39521554/article/details/83348245
https://www.zhihu.com/question/373433479/answer/1030534002

