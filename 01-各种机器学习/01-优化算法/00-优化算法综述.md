# 最优化算法
这个东西说到底就是构建了一个迭代优化学习模型，它的目的是优化，不是建模，所以我们可以用它来优化我们控制器参数，或者优化神经网络参数，或者其他一切参数，但是不能用它来构建模型。


## 最优化算法按照解决方式分为两类
### 1）确定方式、精确算法（Exact Algorithm）
Dantzig建立了线性规划的理论基础，也就是现在最优化理论课上教的东西。这类算法有两种特点。其一，问题的规模往往非常小，一般论文讨论的场景都在10个节点左右，当然随着硬件发展，一般的求解器都能求解100个节点左右的规模了。其二，最后获得的解，必定是最优解。
全局最优算法，主要有单纯形法，Branch and Bound(分枝定界), Cutting plane（割平面）, Danzig-Wolf, Column Generation（列生成）等或其他组合算法例如branch and cut（分枝裁剪法）, branch and pricing（分枝定价）。


### 2）近似方式
对于近似算法，我们一般可分为两类。一，构造法。二，改善法。
构造法包括用最小支撑树的2-近似算法、最近邻法、最近插入法、Greedy法。
改善法包括局部搜索法（包括2-opt，3-opt）、SA法、Tabu Search法、遗传算法。
**另外，实际设计算法时，有一个常用的Idea就是我们用构筑法生成初始解放到改善法里去Improve。**

近似方法分为近似算法和启发式算法，但其实区分两者的界限相当模糊。
a）近似算法（Approximate Algorithm）
根据特定问题使用一些技巧（贪婪策略，限制，划分，断切，松弛）自己设计出来的。比较考验技术，需要给出算法的近似比，复杂度分析，具有很强的推理能力。同样，这类算法的求解规模还是比较受限制的，其最后获得的解不是最优解，但通常可得到一个有质量保证的解。
最经典的就是局部搜索算法，局部搜索算法是对一类算法的统称，符合其框架的算法很多，比如爬山法、模拟退火法和禁忌搜索算法都属于局部搜索算法。

b）启发式算法（Heuristic Algorithm）
启发式算法没有严格的理论分析，是算法设计者根据经验或者观察到的性质设计出来的。通常可找到在传统解决问题的经验中找到寻求一种面向问题的策略，之后用这种策略来在可行时间内寻找一个相对比较好的解，但对解的质量没有保证。
贪心算法的确属于启发式算法的一种形式和应用。

#### 近似算法和启发式算法的比较
就拿牛顿法和遗传算法比较，牛顿法适用于目的明确，然后无限逼近求近似最优解这种问题。遗传算法适合于只有个判断标准但没有明确目标的这种问题。
举些例子:
你随便拽根头发，请问它的直径是多少毫米，这个可以用牛顿法。
如果全球球员任我挑选，如何组建出能赢下一届世界杯的足球队。这个问题只有每场比赛结果这个评判标准出来了，才能迭代出最优组合，这个就适合用遗传算法。
梯度下降法要求函数可微，粒子群算法、遗传算法没有这个要求，即使函数不连续都可以使用（粒子群算法、遗传算法既可以用于组合优化，又可以用于连续优化）。



## 最优化算法按照变量类型为两类
一类是连续变量的问题，另一类是离散变量的问题。

### 1）离散优化/整型优化/组合优化（optimal combination algorithm）
具有离散变量的问题，我们称它为组合的，也就是组合优化。在组合问题里，是从一个无限集或者可数无限集里寻找一个对象——典型地是一个整数，一个集合，一个排列，或者一个图。
组合最优化/离散优化通常都可表述为整数规划问题（除非该离散值全是浮点值）。整数规划与线性规划不同这处只在于增加了整数约束。

#### 广义的整数规划分为以下4种
a）纯整数规划：所有决策变量均要求为整数的整数规划
b）混合整数规划：部分决策变量要求为整数，而另一部分是浮点型的整数规划
c）纯0－1整数规划：所有决策变量均要求为0－1的整数规划。0—1规划方法还可以把多种非线性规划问题表示成整数规划问题。
d）混合0－1规划：部分决策变量均要求为0－1的整数规划
不考虑整数约束所得到的线性规划称为整数规划的线性松弛模型。

### 2）连续优化（continuous optimization）算法
在连续变量的问题里，一般地是求一组实数，或者一个函数。
连续优化算法是机器学习最为常见的算法之一，其中包含一系列已知流行的算法，包括**梯度下降、动量法、AdaGrad 和 ADAM 方法**。

#### 使用连续优化算法的原因
我们考虑过自动设计这些优化算法的问题，这么做有两个原因：
1）首先，很多优化算法是在凸假设下设计的，但被应用到非凸目标函数上；通过在实际使用环境下学习，优化算法有望实现更好的性能。
2）手动设计新的优化算法通常费时费力，可能需要数月或数年之久；学习优化算法可以减少手动设计的劳动量。

#### 连续优化算法通常的工作方式/工作流程
现有的连续优化算法通常的工作方式：
1）它们通常以迭代的方式运行，并保持一定程度的迭代数量，并且每一次迭代都选取目标函数域内的一个点以搜索全局最小。
2）在每个迭代中，算法都会使用固定的更新公式来计算步长向量，然后用它来修正迭代方向与下降步长。
3）更新公式通常是在当前和过去的迭代中所评估历史梯度的函数，这些梯度都是目标函数对不同参数所求的偏导数。
例如：在梯度下降中，更新公式是一些加权的负梯度（所加权为学习率）；在动量法中，更新公式是一些加权的指数移动均值。

## 最优化算法按照优化函数的类型分为两类
### 1）线性规划（Linear programming, 简称LP）
这是运筹学中研究较早、发展较快、应用广泛、方法较成熟的一个重要分支，它辅助人们进行科学管理、寻找线性约束条件下线性目标函数的极值。

### 2）非线性规划
非线性条件下的最优化。当目标函数或约束条件中至少有一个是非线性的函数时，就将这类最优化问题归为非线性规划问题。

常用算法包括：信赖域法、稀疏拟牛顿法、并行计算、内点法和有限存储法等。
a）无约束的非线性规划（无论是否是凸函数、还是非凸函数均可使用）
主要是各种梯度算法，包括最速梯度下降，牛顿法，随机梯度，批量梯度，共轭梯度。
另外，许多约束最优化方法可将有约束问题转化为若干无约束问题来求解。

b）约束最优化方法
主要是拉格朗日乘子法。等式约束（限凸函数）直接使用拉格朗日乘子；不等式约束（需要满足kkt条件）需要使用kkt条件（广义拉格朗日乘子）。

c）常用的一维最优化方法有黄金分割法、切线法和插值法。

d）二次规划也是非线性规划。它的目标函数是二次函数，约束条件是线性的。

## 多目标优化算法
还有一种特殊的优化算法被称之多目标优化算法，它主要针对同时优化多个目标（两个及两个以上）的优化问题，这方面比较经典的算法有NSGAII算法、MOEA/D算法以及人工免疫算法等


## 常用工具
主流的求解器（CVX，cplex等）还不支持启发式算法，因此不建议用它们求解大规模（very large）问题。好像gurobi可以，不过商用的应该很贵。
Cplex是IBM出的一款科学计算软件
下整数规划求解器，例如Cplex，Gurobi和Xpress。这些求解器（算法包）已经为各位写好了复杂的分支定界和上面提到的启发式、割平面算法等等
整数规划问题，建议使用Lingo软件求解
找到两个非常值得一试的开源工具，“VRP Spreadsheet Solver”和Google的Or-Tools。
启发式算法找到一个较好的开源包scikit-opt。


变量部分限制为整数的，称混合整数规划。理论求解方法分类：
（i ）分枝定界法—可求纯或混合整数线性规划。
（ii ）割平面法—可求纯或混合整数线性规划。
（iii ）隐枚举法—求解“0-1”整数规划：过滤隐枚举法；分枝隐枚举法。
（iv ）匈牙利法—解决指派问题（“0-1”规划特殊情形）。
（v ）蒙特卡洛法—求解各种类型规划。


CPLEX里面不少算法都是 全局最优 算法，例如单纯形法，分支定界法。启发式算法一般无法保证 全局最优性。

软件工具包（cplex, gurobi, glpk，lpsolve, scip ...）给出经典运筹优化问题的baseline解

# 参考资料
https://www.zhihu.com/question/316175486/answer/625107236
https://www.zhihu.com/question/359478415/answer/1059506754
https://www.zhihu.com/question/21860147/answer/19542766
