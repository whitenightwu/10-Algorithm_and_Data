# 演化学习（属于启发式算法中的一类）
## 种类
演化学习是一种优化算法，是一种贪心算法，是启发式优化算法的一个重要家族，又被称为meta-heuristics(元启发算法)。
演化算法是一个受益于自然演化的大型启发式随机优化算法，演化算法在模拟自然演化的过程过主要考虑了两个关键因素（变分再生产和优选）。
这个东西说到底就是构建了一个迭代优化学习模型，它的目的是优化，不是建模，所以我们可以用它来优化我们控制器参数，或者优化神经网络参数，或者其他一切参数，但是不能用它来构建模型。

进化算法，或称“演化算法” (evolutionary algorithms) 是一个“算法簇”，尽管它有很多的变化，有不同的遗传基因表达方式，不同的交叉和变异算子，特殊算子的引用，以及不同的再生和选择方法，但它们产生的灵感都来自于大自然的生物进化。与传统的基于微积分的方法和穷举法等优化算法相比，进化计算是一种成熟的具有高鲁棒性和广泛适用性的全局优化方法，具有自组织、自适应、自学习的特性，能够不受问题性质的限制，有效地处理传统优化算法难以解决的复杂问题。
不同的演化算法，主要在于其启发式算子、评价准则、停止准则等部件的设计不同。

## 常见的演化算法
广义的演化算法包括：模拟退火算法、蚁群算法、粒子群算法等等。**比群智能算法的范围更广！**

## 演化算法的分析
演化策略通常将优化视为一个模拟的过程（optimization-as-a-simulation）。用户在模型总体（a population of models）上指定一个动态系统，并且在模拟的每个时间步长，根据动态系统的规则更新这个总体。模型可能会也可能不会相互影响。模拟进行下去，希望系统的动力学最终能够诱导这个总体汇聚成“好的模型”。

演化算法通常维护一个解的集合，并通过启发式算子来从现有的解产生新解，并通过挑选更好的解进入下一次循环，不断提高解的质量。

可见，演化算法进行优化的过程不依赖于梯度等信息，也常被称为0阶优化方法、无梯度(derivative free)优化方法、黑箱优化方法等；也因此能够用于处理非凸、高度非线性、组合优化、目标函数未知等问题。

机器学习任务中存在大量的复杂优化问题有待解决，这就使得机器学习与演化算法的结合，即演化学习有了自然的动机和天然的条件。
很多学者已经尝试将演化算法应用于分类、聚类、规则发现、特征选择等等诸多机器学习与数据挖掘问题上。

## 演化算法通常具有公共的算法结构
1）产生初始解集合，并计算解的目标函数值；

2）使用启发式算子从解集合产生一批新解，并计算目标函数值，并加入解集合；

3）根据启发式评价准则，将解集合中较差的一部分解删除；

4）重复第二步，直到设定的停止准则满足；

5）输出解集合中最优的解。


## 缺点
由于演化算法作为优化算法的理论性质缺失，其优化效率高低、求得解的逼近程度如何、启发式算子有何效用等等问题难以有严格的答案，演化学习也因此缺乏有效的理论解释。

最近，演化学习在理论基础方面得到发展。针对演化算法的理论分析工具开始出现，演化算法求解的逼近性能开始得到了揭示，启发式算子的效用也逐渐被了解。

值得一提的是，近来演化学习方法在理论上和实验上都显出超越经典学习方法的潜力。

同时，在大数据环境下，演化学习的进一步发展也面临挑战：当学习模型变得复杂、面临的数据增长迅速、对模型训练时间的要求苛刻时，演化学习如何能够进行有效、高速的优化，还有待深入的研究。



## 演化学习与优化算法的关系
对于优化问题的解决方法，可以分为两类：
1）确定方式

2）近似方式，近似方法分为近似算法和启发式算法。其中，近似算法通常可得到一个有质量保证的解；而启发式算法通常可找到在传统解决问题的经验中找到寻求一种面向问题的策略，之后用这种策略来在可行时间内寻找一个相对比较好的解，但对解的质量没有保证。贪心算法的确属于启发式算法的一种形式和应用。
