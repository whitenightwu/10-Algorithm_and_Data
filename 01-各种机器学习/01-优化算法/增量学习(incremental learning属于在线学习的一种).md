# 增量学习(incremental learning)
增量学习是指一个学习系统能不断地从新样本中学习新的知识，并能保存大部分以前已经学习到的知识。增量学习非常类似于人类自身的学习模式。因为人在成长过程中，每天学习和接收新的事物，学习是逐步进行的，而且，对已经学习到的知识，人类一般是不会遗忘的。

增量学习思想可以描述为：每当新增数据时，并不需要重建所有的知识库，而是在原有知识库的基础上，仅对由于新增数据所引起的变化进行更新。
当新课程的培训逐渐增加时，整体表现急剧下降。这是由于当前的神经网络架构需要整个数据集，包括来自旧类和新类的所有样本，以更新模型 - 随着类数量的增加，这一要求变得容易不可持续。

**与增量学习对应的，有一种称为减量学习（decremental learning），它们俩都属于在线学习（online learning），即在线学习包括了incremental learning和decremental learning。**


## 作用以及重要性
增量学习思想的重要性体主要在2个方面：

1）在实际的感知数据中，数据量往往是逐渐增加的，因此，在面临新的数据时，学习方法应能对训练好的系统进行某些改动，以对新数据中蕴涵的知识进行学习；

2）对一个训练好的系统进行修改的时间代价通常低于重新训练一个系统所需的代价。


## 特点
许多作者甚至将增量学习等同于在线学习（大多数情况是这样的，但其实在线学习是分为增量学习和减量学习的）。这里，引用Robipolikar对增量学习算法的定义，即一个增量学习算法应同时具有以下特点:

1)可以从新数据中学习新知识;

2)以前已经处理过的数据不需要重复处理;

3)每次只有一个训练观测样本被看到和学习;

4)学习新知识的同时能保存以前学习到的大部分知识;

5)—旦学习完成后训练观测样本被丢弃;

6)学习系统没有关于整个训练样本的先验知识;


## 常见的增量学习算法
### 1）自组织增量学习神经网络
自组织增量学习神经网络（SOINN）是一种基于竞争学习的两层神经网络。SOINN的增量性使得它能够发现数据流中出现的新模式并进行学习，同时不影响之前学习的结果。因此SOINN能够作为一种通用的学习算法应用于各类非监督学习问题中。

SOINN是两层结构（不包括输入层）的竞争性神经网络，它以自组织的方式对输入数据进行在线聚类和拓扑表示，其工作过程如图一所示。第1层网络接受原始数据的输入，以在线的方式自适应地生成原型神经元来表示输入数据。这些节点和它们之间的连接反映了原始数据的分布情况；第2层根据第1层网络的结果估计出原始数据的类间距离与类内距离，并以此作为参数，把第1层生成的神经元作为输入再运行一次SOINN算法，以稳定学习结果。

### 2）情景记忆马尔可夫决策过程
情景记忆马尔可夫决策过程EM-MDP准确来说是一套完整的人工智能方案（简化版），这个框架中包括对情景的认知、增量学习、短期与长期记忆模型。

我们将焦点放在框架中的增量学习部分。该框架基于自适应共振理论（ART）与稀疏分布记忆（SDM）的思想实现对情景记忆序列的增量式学习。相比SOINN网络每次最多只能有一个输出节点，该方法具有环境适应性好的优点。

### 3）结合深度学习
我们通过逐步学习深度神经网络的方法来解决这个问题，使用新数据并且只使用与旧类中的样本相对应的小样本集。这是基于由蒸馏措施组成的损失，以保留从旧类中获得的知识，以及用于学习新类的交叉熵损失。

### 增量学习常出现于决策树，甚至会与多核学习结合

## 增量学习实例
在模型更新中，这里主要还是以增量更新为主，在模型设计之初，有两条路向前推进：一个是模型的实时性，一个是特征的实时性。我们面临过这个问题的选择，其实两者代表系统实时性不同的维度，每个方向去提升实时性的话，都意味着会付出大量的代价，有工程的代价，也有系统设计难度的代价。基于自身业务去考虑，我们最终选择了重特征的实时性，轻模型的实时性。在示意图中，左面是小时级的特征，通过训练，增量的对模型进行更新；右面是通过全量样本对模型进行全量的full-batch更新，因为如果一直使用增量模型，时间长了会产生一定的偏差，偏差累积效应会影响线上效果，因此，定期的全量更新是必须的。

相比离线特征，现在的实时这块已经做到了秒级的更新。而如果增加模型的实时性意味着能更快的捕捉新的特征，或者让模型学习到特征与特征之间的泛化关系。在资讯信息流的推荐中，能捕捉到的比如当前的热点、人群的、兴趣的全局变化，通过结合自身的业务，发现，比如说热点、兴趣、人群的变化在一段时间内是稳定的，特征之间的泛化并不会那么大，比如看美食类的用户多半也看看养生、娱乐等等。所以这里模型的更新选择小时级是一个比较好的对资源的权衡。